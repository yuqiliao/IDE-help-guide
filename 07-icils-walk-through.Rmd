# ICILS IDE Walkthrough {#icilswalkthrough}

There are four general steps for exploring each IDE page (see exhibit 3). Each step is described in more detail in the following sub-sections. 

Exhibit 3. What you will see in the IDE environment and what each step entails
```{r chapter7-1, echo=FALSE, fig.align='center', out.width="50%"}
knitr::include_graphics('images/chapter7/four-steps.png')
```


## 1. Select Criteria

### 1.A. Overview

Your data query in the ICILS IDE begins on the **Select Criteria**
screen (see exhibit 3).

Select a **Display** from the drop-down menu. Once the screen resets,
you can choose one or more **Years**, **Measures**, and
**Jurisdictions** for the data you wish to view or compare. Use the
**Reset** button, located in the upper-right portion of the screen (just
below the **Help** button), to cancel your selections and begin again.

Click on a blue sideways-facing arrow (►) to open up a category and
click on a blue downward‑facing arrow (▼) to close a category.

Exhibit 3. Selecting criteria

![Exhibit 3 is a screenshot from the ICILS IDE tool showing the Select
Criteria tab.](images/chapter7/image2.png){width="6.5in"
height="5.111805555555556in"}

### 1.B. Choose Display

Under **Display**, you have the choice of **Student** and **Teacher**,
which corresponds to running either a student- or teacher-level
analysis. Selecting the Student option in the display drop-down list
provides student or school information that is an attribute of students
(with estimates reported, for example, as the "percentage of students"),
while selecting the Teacher option provides teacher or school
information that is an attribute of teachers (with estimates reported,
for example, in terms of the "percentage of teachers"). Once a display
is chosen, the screen resets and you can select **Year**(s),
**Measure**(s), and **Jurisdiction**(s).

### 1.C. Choose Year

At the top of the **Measure** and **Jurisdiction** sections, you have
the choice of selecting 2018 and/or 2013 by checking the appropriate
box. To include data from both years, check the "All Years" box to the
left of the individual years. CIL data is available for both years, and
CT data is available for 2018.

### 1.D. Choose Measure

After choosing a display, you can choose one or more outcome variables
under Measure, including the overall scales for CIL or CT (Student
display only) and other continuous variables. These variables fall into
different categories. For example, the variable "Age of student" can be
found in the Student demographics category in the Student display, and
the variable "About You/ Year Teaching Started" can be found in the
Teacher demographics category in the Teacher display.

Some of the continuous variables may have missing values if there are
cases that did not answer the assessment or the questionnaire. In both
the Student and Teacher displays, selecting the variable "Percentage
across full sample" under the *Population* category will allow you to
calculate percentage statistics based on the full sample.

### 1.E. Choose Jurisdiction

With your **Measure**(s) and **Year**(s) selected, next choose at least
one **Jurisdiction**.

Jurisdictions are found under the following groups: **Countries** and
**Benchmarking participants.** There is also a group category called
**Average**, with options to display the **Average of Countries** and
the **Average of the Selected Jurisdictions**.

The general procedures for selecting one or more jurisdictions are as
follows:

1.  To open or close jurisdictions, click on the arrow. Jurisdictions in
    > the group are open and can be selected when the blue arrow points
    > down (see exhibit 4).

2.  Click the checkboxes next to the specific jurisdictions that you are
    > interested in or uncheck those jurisdictions that you wish to
    > deselect. If you click the checkbox next to the group name (e.g.,
    > "Countries"), you will select all the jurisdictions within that
    > group. If desired, uncheck the group name to deselect all.

3.  If you want to close a group (for example, close the list of
    > countries in order to readily see the Benchmarking participant
    > jurisdictions), click the blue arrow next to the group name. The
    > closed group's arrow points to the right. Be advised that closing
    > the group will not deselect your choices.

Exhibit 4. Choosing jurisdictions

![Exhibit 4 is a screenshot from the ICILS IDE tool showing
jurisdictions available in the Select Criteria
tab.](images/chapter7/image3.png){width="6.5in" height="5.1305555555555555in"}

To continue in the IDE, click the **Select Variables** button at the
bottom right of the page or the tab at the top of the page to go to the
next screen (see exhibit 4).

## 2. Select Variables

### 2.A. Overview

Step 2, **Select Variables**, can only be accessed after choosing
criteria at step 1, **Select Criteria**.

To continue your data query and edit a report, *you must choose at least
one variable on this screen.* You can browse for variables using the
**Category** and **Sub Category** lists or by using the **Search**
function (see exhibit 5). You can return to this screen to change
variable selections at any time.

Exhibit 5. Select variables overview

![Exhibit 5 is a screenshot from the ICILS IDE tool showing an overview
of the Select Variables tab.](images/chapter7/image4.png){width="6.5in"
height="4.470138888888889in"}

### 2.B. Search Using Category and Sub Category Lists

On the **Select Variables** screen, choose at least one variable for
your report. One way to do this is to search for variables using the
**Category** and **Sub Category** lists. If you don't wish to choose
from any of the specified categories and subcategories, then select
**All students** in the **All Students** category.

The variables shown are tied to the criteria you selected at step 1
(**Measure**, **Year**, and **Jurisdiction**), which are indicated at
the top of the screen. To change any of these criteria, return to step
1, **Select Criteria**.

To browse for variables, get details about them, select them, and view
them:

1.  Click the blue arrows to open and close categories and subcategories
    > of variables (see exhibit 6).

```{=html}
<!-- -->
```
4.  Click **details** or **hide details** to show or hide the full title
    > of a given variable, the ICILS ID, and the values (i.e., value
    > labels). Note that some variables have the same or similar short
    > titles, but comparing details will show you how they differ. See
    > the example in exhibit 6, which shows two **Immigration status**
    > variables (SIMMIG and SIMMBGR). The differences between these two
    > variables are described in the details.

5.  Click the checkbox next to a variable to select it for your
    > analysis/report. You will see the count increase next to **View
    > Selected**.

6.  Click the **View Selected** tab to see the variables you have
    > chosen. To return to the full list of variables by category, click
    > the **View All** tab.

7.  Remember to select the year for which you wish to build a report and
    > make sure that data are available for your chosen year and
    > variables.

8.  Searching for variables is an option from the **Search** box. See
    > **Section 2.C. Search Function** for more details about this
    > function.

Exhibit 6. Select variables using category and sub category lists

![Exhibit 6 is a screenshot from the ICILS IDE tool showing how to
select a variable from the categories and sub categories listed in the
Select Variables tab.](images/chapter7/image5.png){width="6.5in"
height="4.495138888888889in"}

When you have selected the variable(s) you want to include, continue by
clicking the **Edit Reports** button at the bottom of the page or the
tab at the top of the page to go to the next screen.

### 2.C. Search Function

The second way to search for variables is to use the **Search** function
on the **Select Variables** screen.

Type a term in the **Search** box and click **Go** (or hit "Enter" on
your keyboard) to find variables by keywords in the question and/or
details for the variable (see exhibit 7). If you use multiple keywords,
"and" is assumed. You can narrow your search by using "or," "not," or
"and not." The search function operates on an exact phrase if it is
contained in quotes. The variable(s) that include the search term(s) in
the question or its details will be listed in the search results.

Exhibit 7. Select variables using the search function

![Exhibit 7 is a screenshot from the ICILS IDE tool showing how to
select a variable using the search
function.](images/chapter7/image6.png){width="6.5in"
height="4.479861111111111in"}

When you have selected the variable(s) you want to include, continue by
clicking the **Edit Reports** button at the bottom of the page or the
tab at the top of the page to go to the next screen.

## 3. Edit Reports

### 3.A. Overview

You can access step 3, **Edit Reports**, after choosing criteria at step
1, **Select Criteria**, and choosing variables at step 2, **Select
Variables**. The IDE will automatically build reports based on your
selections from steps 1 and 2. However, at step 3, you may modify your
selections for each report.

At this step, you can

-   preview and edit the layout of your reports;

-   copy reports or create new reports based on the variables selected;

-   change formatting options, such as the number of decimal places to
    display, for all reports (these may also be changed in individual
    reports);

-   change statistics options, such as averages, for all reports (these
    may also be changed in individual reports, but statistics options
    can overwrite previous edits);

-   select reports to be built into tables and charts at step 4, **Build
    Reports**; and

-   delete reports.

Using your chosen criteria, the IDE will return a separate data report
for each variable you have chosen. If you have selected two or three
variables (not counting **All Cases**), you will also see a
cross-tabulated report for these variables. If you have chosen four or
more variables, you will get tables for each variable, but you won't get
the cross-tabulation. If your selected criteria include more than one
measure (e.g., an overall scale and one or more continuous variables), a
separate set of data reports will be generated for each measure (see
exhibit 8).

**Exhibit 8. Edit reports overview**

![Exhibit 8 is a screenshot from the ICILS IDE tool showing an overview
of the Edit Reports tab.](images/chapter7/image7.png){width="6.5in"
height="3.7284722222222224in"}

The **Edit Reports** step shows overview information of your reports.
The **Report** column indicates the report, or cross-tabulation report,
number based on the variable(s) chosen during the criteria selection.
Under the **All** tab, reports may be chosen for the report-building
phase, either by selecting **All** or selecting individual reports. The
**Action** column gives you the option to **Preview**, **Edit**,
**Delete**, or **Copy** the report. The **Measure** column shows which
measure the report will portray. The **Variable** column indicates the
variable(s) included in the report. The **Year** column shows which
years you have selected for comparison. The **Jurisdiction** column
shows the countries and subnational education systems selected for
comparison, and the **Statistic** column provides the type of statistic
output that will be generated in the report-building phase.

### 3.B. Preview Report

Select **Preview**, in the **Action** column (see exhibit 8), to see how
your report will be laid out. The preview will not provide actual data
but will show how the data will be arranged in rows and columns (see
exhibit 9). You can select **Preview** at any time to see how your
changes will affect the report's final layout.

Exhibit 9. Using preview report

![Exhibit 9 is a screenshot from the ICILS IDE tool showing an example
of the preview function that is available in the Edit Reports
tab.](images/chapter7/image8.png){width="6.5in" height="2.8618055555555557in"}

### 3.C. Edit Report

To edit the report, select the **Edit** command, in the **Action**
column, next to the report number (see exhibit 8). (Another way to edit
a report is to select the **Edit** tab when you are previewing a
report.) The following can be done using the edit function (see exhibit
10):

1.  Name your report. You have the option of giving each report a
    > distinctive name, up to a limit of 50 characters, using only
    > letters, numbers, spaces, underscores, and hyphens. (Otherwise, by
    > default, the report is named Report 1, Report 2, etc., or
    > Cross-Tabulated Report 1, Cross-Tabulated Report 2, etc.)

```{=html}
<!-- -->
```
9.  Select a measure. You can choose a measure if more than one was
    > selected at step 1.

10. Select which jurisdictions, variables, years (if applicable), and
    > statistics to include (out of the selections previously made at
    > steps 1 and 2). You can select up to two statistics options from
    > the following: averages, standard deviations, percentages, and
    > percentiles. (For further information, see **Section 3.G.
    > Statistics Options**.)

11. To create a new variable while editing a report, click on **Create
    > New...** under the **Variable** heading. Section 3.D. below
    > explains the process for creating a new variable.

12. Change the table layout by dragging elements to determine which
    > items will appear in rows and which will appear in columns. Some
    > of the arrangements will not be permissible, but a pop-up alert
    > will explain this.

Exhibit 10. Editing reports

![Exhibit 10 is a screenshot from the ICILS IDE tool showing an example
of the editing report function that is available in the Edit Reports
tab.](images/chapter7/image9.png){width="6.5in" height="4.870138888888889in"}

To save changes, make sure to select **Done** in the upper-right portion
of the screen before closing the **Edit Report** window.

### 3.D. Create New Variables

The levels of a categorical variable can be collapsed to create a new
variable. To do so, select **Edit**, in the **Action** column, and
select **Create new...** under **Variable** (see exhibit 10). The new
variable is created by combining values for an existing variable. The
steps are as follows:

1.  Click **Create new\...** under the **Variable** heading.

2.  Select the variable for which you wish to combine values.

```{=html}
<!-- -->
```
13. Select the values you want to combine by checking the boxes to the
    > left of the values (see exhibit 11).

14. Create a name for the new value, and press **Create**. The collapsed
    > values will appear in gray to indicate that they have already been
    > used.

15. Wait for the screen to refresh, and press **Done**.

16. The new variable will appear in the **Variable** list in the **Edit
    > Report** window or **Create New Report** window, designated as
    > "collapsed."

17. Check the box next to the new variable to view it in the report. You
    > can click **Preview** to see how the table will be laid out before
    > retrieving data.

Exhibit 11. Creating new variables

![Exhibit 11 is a screenshot from the ICILS IDE tool showing an example
of the creating new variable function that is available in the Edit
Reports tab.](images/chapter7/image10.png){width="3.590200131233596in"
height="4.0in"}

A new variable that you create is applicable only to a specific report;
it does not apply to the other reports listed on the **Edit Reports**
screen. For example, if you selected multiple measures of the overall
scale CIL for analysis, then you would need to create the new variable
for each measure, or create a copy of the report and edit it
accordingly. To do the latter, click on **Copy** report on the **Edit
Reports** screen (see exhibit 8). The copied report will appear at the
end of the list of reports. Then, for the new copy, click on **Edit**
(using the above example, you can change the measure and give the report
a new name).

You can repeat the process and combine different values of a variable to
create additional new variables. Using the **Create New Report**
function, you can create a new report for each new variable that you
create. (For further information, see **Section 3.E. Create New
Report**, below.)

If you selected two or three variables from which to create new
variables, you can repeat the process for each of them. Using the
**Create New Report** or **Edit Report** function, these collapsed
variables will be listed and available for cross-tabulation (see exhibit
12). If you have chosen four or more variables (not counting **All
Cases**), you won't get the cross-tabulation. You can click **Preview**
to see how the table will be laid out before retrieving data.

Exhibit 12. Edit reports with collapsed variables

![Exhibit 12 is a screenshot from the ICILS IDE tool showing an example
of the editing report with collapsed variables function that is
available in the Edit Reports tab.](images/chapter7/image11.png){width="6.5in"
height="4.870138888888889in"}

### 3.E. Create New Report

From the main **Edit Reports** screen, clicking on **Create New Report**
brings up the same options as **Edit Report**, but with no checkboxes
marked and without any new variables you may have created. Thus,
**Create New Report** provides a clean slate for your selections from
the first two steps, **Select Criteria** and **Select Variables** (see
exhibit 13). Each new report you create will appear at the end of the
list of reports. If you do not give the report a specific name, it will
be called "New Report."

Exhibit 13. Creating new reports

![Exhibit 13 is a screenshot from the ICILS IDE tool showing an example
of the creating new report menu that is available in the Edit Reports
tab.](images/chapter7/image12.png){width="6.5in" height="4.854861111111111in"}

### 3.F. Format Options

From the main **Edit Reports** screen, clicking on **Format Options**
will allow you to make formatting changes applicable to all the reports
listed. The following formatting options are available using this
function (see exhibit 14):

1.  **Variable Labels (Long)** displays a more detailed description of
    > the variables selected in a query than the default short label.
    > For variables from questionnaires, the full text of the question
    > is displayed. Be advised that the length of the extra detail may
    > sometimes interfere with table formatting.

```{=html}
<!-- -->
```
18. **Show data for values categorized as "missing"** will include the
    > percentage of students in the total sample or in a reporting group
    > for whom membership in a particular response category is unknown
    > because no response was given by the students, their teacher, or
    > their school. The percentage of "missing" will be shown in the
    > right-most table column. Missing data are available only for
    > queries that involve percentages as the statistic type. Unless you
    > check this option, the default is for missing responses not to be
    > included in the percentage distribution shown.

19. **Year Order** gives you the option to display either the most
    > recent year first or the oldest year first.

20. **Decimal Places** allows you to specify the level of precision for
    > a particular statistic. Depending on the value range of the
    > dependent variable---for example, the dependent variable "ICILS
    > Computer and Information Literacy: Overall \[PVCIL\]" ranges from
    > 100 to 700; the dependent variable "Computer experience in years
    > \[SEXCOMP\]" ranges from 0 to 4---the default number of decimal
    > places for a report can vary from zero to three. Also, standard
    > errors will be shown to one more decimal place than is shown for
    > their respective statistic. For example, if you request that
    > average scores be displayed to one decimal place (by default,
    > average scores are rounded to the nearest whole number), the
    > corresponding standard errors will display two decimal places. If
    > you export to Excel, you will be able to increase the number of
    > decimal places in most cases. Note that only integer-level
    > precision is allowed for percentages; that is, the number of
    > decimal places is fixed at "none" for percentages, and the
    > corresponding standard errors are shown to one decimal place.

21. **Include** gives you the option of showing standard errors. By
    > default, standard errors are shown inside parentheses, but you can
    > choose to show them without parentheses*.* You can preview the
    > effects of your selection in the **Sample Display** area (see the
    > blue‑shaded box at the bottom of exhibit 14 below).

Exhibit 14. Format options

![Exhibit 14 is a screenshot from the ICILS IDE tool showing an example
of the format options available in the Edit Reports
tab.](images/chapter7/image13.png){width="2.9212576552930885in"
height="4.326202974628171in"}

Be advised that the choices you make in the **Format Options** window
will apply to all reports and cannot be changed for individual reports.
Use the **Reset** button, located in the upper-right portion of the main
**Edit Reports** screen (just below the **Help** button), to restore the
**Format Options** to the default settings (although caution is advised,
as this will also delete any new reports that you have created).

### 3.G. Statistics Options

Available only from the main **Edit Reports** screen, clicking on
**Statistics Options** allows you to designate up to two statistics. The
selections you make are applicable to all the reports listed, although
you can also change the statistics for an individual report when you
edit it. (For further information, see **Section 3.C. Edit Report**.)

The following statistics options are available (see exhibit 15):

1.  **Averages.** This statistic provides the average value for a
    selected continuous variable or score (i.e., the overall scale for
    CIL or CT). For the ICILS assessment, student performance is
    reported on scales that range from 100 to 700. By default, the
    standard errors of the scores are shown in parentheses.

2.  **Standard deviations.** The standard deviation is a measure of how
    widely or narrowly dispersed scores are for a particular dataset.
    Under general normality assumptions, 95 percent of the scores are
    within two standard deviations of the mean. For example, if the
    average score of a dataset is 500 and the standard deviation is 100,
    it means that 95 percent of the scores in this dataset fall between
    300 and 700. The standard deviation is the square root of the
    variance.

3.  **Percentages.** This statistic shows the percentage of students as
    a row percentage. For example, if the first column lists countries,
    then each country will display its own percentage distribution
    across its row. By default, percentage distributions do not include
    missing data. For information on how to show data for values
    categorized as missing, see **Section 3.F. Format Options**.

4.  **Percentiles.** This statistic shows the threshold (or cutpoint)
    score for the following:

    10^th^ percentile -- the bottom 10 percent of students

    25^th^ percentile -- the bottom quarter of students

    50^th^ percentile -- the median (half the students scored below the
    cutpoint and half scored above it)

    75^th^ percentile -- the top quarter of students

    90^th^ percentile -- the top 10 percent of students

Exhibit 15. Statistics options

![Exhibit 15 is a screenshot from the ICILS IDE tool showing an example
of the statistics options available in the Edit Reports
tab.](images/chapter7/image14.png){width="3.7291666666666665in" height="4.75in"}

As previously noted, the selections you make in **Statistics Options**
will be applied automatically to all reports, although you can change
the statistics for an individual report when you edit it. Be advised
that if you use **Statistics Options** after editing the statistics in
one or more of your individual reports, the statistics options selected
will overwrite your previously edited selections. If you wish to use the
same criteria and variables in a report with a different selection of
statistics, consider using the **Create New Report** function to
generate a new report with different statistics. (For further
information, see **Section 3.E. Create New Report**.) You can also make
a copy of an individual report.

You can use the **Reset** button, located in the upper-right portion of
the main **Edit Reports** screen (just below the **Help** button), to
restore the **Statistics Options** to the default setting, which is
averages for all reports (this will also delete any new reports that you
created).

Not all statistics are available for all reports. Their availability
depends on other selections you have made to define the content and
format of your report:

-   Percentages will not display if jurisdictions or years appear in
    columns.

-   If proficiency levels are selected in the variable section, only
    average scores and percentages will be displayed.

Please note that results obtained from the IDE might not always match
those published by IEA or NCES. This is due to the use of different
reporting standards, such as suppression rules related to sample size
and suppression due to response rates.

### 3.H. Select Reports to Build

As you edit your reports, you can give them distinct names (up to 50
characters) to differentiate them, as well as make changes to the
jurisdictions and variables previously selected, the statistics, and the
layout of the rows and columns. (For further information, see **Section
3.C. Edit Report**.) You may make copies of reports with these changes.
To proceed to step 4, **Build Reports**, each report for which you want
to retrieve data should be previewed using the **Preview** function. To
decrease processing time as you move to step 4, you can uncheck any
reports for which you do not wish to retrieve data. By default, all
reports are checked. To uncheck one or more reports, you can either
uncheck the reports individually or click on the **All** box. (Doing the
latter will uncheck all of the reports and allow you to check only those
for which you wish to retrieve data.) In the example that follows (see
exhibit 16), data will be retrieved for all reports.

Exhibit 16. Selecting reports to build

![Exhibit 16 is a screenshot from the ICILS IDE tool showing how to
select reports to build in the Edit Reports
tab.](images/chapter7/image15.png){width="6.5in" height="3.790277777777778in"}

If you wish to delete a report from the list of reports, click
**Delete** (see 1 above) in the **Action** column. Use the **Reset**
button, located in the upper-right portion of the screen (see 2 above),
to restore the deleted reports (although caution is advised, as this
will also delete any new reports that you created and restore the
**Format Options** and **Statistics Options** to the default settings).

To continue to the last step in the IDE, click the **Build Reports**
button at the bottom of the page (see 3 above) or the tab at the top of
the page to go to the next screen.

## 4. Build Reports

### 4.A. Overview

You can access step 4, **Build Reports**, after choosing criteria at
step 1, **Select Criteria**, in which case the default report built will
provide data for just averages and for the **All Cases** variable. After
step 1, you may also go on to steps 2 and 3, where you can select
additional variables and edit reports, before moving on to **Build
Reports**. In **Build Reports**, you can do the following:

1.  Generate a data table for each report as shown in the **Select
    > Report** drop-down feature (see 1 in exhibit 17). By default, all
    > reports are checked at step 3, although you can uncheck any
    > reports for which you do not wish to retrieve data. (For further
    > information, see **Section 3.H. Select Reports to Build**.)

```{=html}
<!-- -->
```
22. Export and save data tables into various formats using the **Export
    > Reports** button (see 2 in exhibit 17). The output formats include
    > HTML (print-friendly), Microsoft Excel, Microsoft Word, and Adobe
    > PDF.

23. Select the **Chart** tab (see 3 in exhibit 17) to create and
    > customize charts for each report and save them for export in the
    > above formats.

24. Select the **Significance Test** tab (see 4 in exhibit 17) to run a
    > significance test on your results, customize it, and export it.

25. Select the **Gap Analysis** tab (see 5 in exhibit 17) to run a gap
    > analysis on your results, customize it, and export it.

26. Select the **Regression Analysis** tab (see 6 in exhibit 17) to run
    > a regression analysis on your results, customize it, and export
    > it.

Exhibit 17. Building reports overview

![Exhibit 17 is a screenshot from the ICILS IDE tool showing an overview
of the Build Reports tab featuring the Select Report, Export Reports,
Chart, Significance Test, Gap Analysis, and Regression Analysis
options.](images/chapter7/image16.png){width="6.5in" height="4.76875in"}

### 4.B. View Reports as Data Tables

Some reports will take longer than others to process, so do not hit the
"Back" button on your browser once you have clicked on **Build Reports**
(see exhibit 18). Your table will appear once the processing is
complete. To select a different table to view, go to the **Select
Report** drop‑down menu (see 1 in exhibit 17) and choose the table of
interest. To change the formatting or statistics options of a table or
to generate a table from a report not included in your selection, return
to step 3, **Edit Reports**.

Exhibit 18. Processing data![Exhibit 18 is a screenshot from the ICILS
IDE tool showing data processing in the Build Reports
tab.](images/chapter7/image17.png){width="6.5in" height="3.286111111111111in"}

### 4.C. Charts

To create a chart, go to **Select Report** on the **Build Reports**
screen to choose the report of interest from the drop-down menu, and
then click the **Chart** link (see exhibit 19).

You will be able to create many types of charts and customize them.
**Section 4.E. Create Charts -- Chart Options** provides a summary of
the available features and how they can be customized.

Exhibit 19. Viewing reports as charts

![Exhibit 19 is a screenshot from the ICILS IDE tool showing how to
select the chart creating function in the Build Reports
tab.](images/chapter7/image18.png){width="6.5in" height="2.1256944444444446in"}

### 4.D. Create Charts

When you click **Chart**, you will first make selections of
**Jurisdiction**, **Year**, **and** **Statistic** (see exhibit 20). All
**Jurisdictions** and **Years** are selected by default, while you can
only choose one **Statistic**. Uncheck any of the criteria that you do
not wish to chart, as long as you have one selected in each category.

Only the statistics option(s) used to report data in the previous step
will be presented, and only one statistics option can be selected at a
time. For example, **Percentiles** will appear as the only data option
to build the chart if the table created in the previous step is
reporting data with only percentiles selected as the statistics option.

Once you are finished with the Data Options, click the **Create**
**Chart** button in the lower-right corner of the screen.

Exhibit 20. Data options for charts

![Exhibit 20 is a screenshot from the ICILS IDE tool showing the data
options available in the chart creating function in the Build Reports
tab.](images/chapter7/image19.png){width="6.5in" height="6.646527777777778in"}

### 4.E. Create Charts -- Chart Options

Next, you can make selections regarding the chart options located at the
bottom of the same window.

1.  Select **Bar Chart**, **Column Chart**, or **Line Chart** (see 1 in
    > exhibit 21). If the Percentages Statistic is selected, you can
    > select from a **Percentage Chart** option. If the Percentiles
    > Statistic is selected, you can also select from a **Percentiles
    > Chart** option.

2.  After selecting a chart type, change any data dimensions from the
    > drop-down menus for **Bar**, **Column**, or **Line Values** and
    > **Values Grouped by** (see 2 in exhibit 21). Any new variables
    > that you created at step 3, **Edit Reports**, will be available
    > for selection, but only if you selected the variables (by clicking
    > the checkbox next to them) and clicked **Done** after you edited
    > the report.

3.  Create your chart by clicking the **Create Chart** button in the
    > lower-right corner (see 3 in exhibit 21).

**Exhibit 21. Chart options**

![Exhibit 21 is a screenshot from the ICILS IDE tool showing the chart
options available in the chart creating function in the Build Reports
tab.](images/chapter7/image20.png){width="6.5in" height="6.666666666666667in"}

While previewing your chart, you can do the following (see exhibit 22 as
an example of a **Percentile Chart** and exhibit 23 as an example of a
**Bar Chart**):

1.  Use the drop-down menus to change the jurisdiction and other
    > variables as applicable.

2.  Place your cursor over the bars of the chart to see the data points
    > and value label(s).

Exhibit 22. Percentile chart

![Exhibit 22 is a screenshot from the ICILS IDE tool showing a preview
of a percentile chart in the chart creating function in the Build
Reports tab.](images/chapter7/image21.png){width="6.5in" height="5.05625in"}

Exhibit 23. Bar chart

![Exhibit 23 is a screenshot from the ICILS IDE tool showing a preview
of a bar chart in the chart creating function in the Build Reports
tab.](images/chapter7/image22.png){width="6.5in" height="4.28125in"}

You can choose "**Back to Chart Options**" (located in the upper-left
corner, below the **Chart** link) to make more changes.

To make an additional chart from the same report or table, click the
**Chart** link on the **Build Reports** screen. It is recommended that
you provide a new chart name (the default is Chart 1, Chart 2, etc.). If
you don't start the process again by clicking the **Chart** link, the
new chart will overwrite the previous one.

If you wish to make charts from other reports, select another report in
the **Select Report** drop‑down list. If other reports were not checked
in step 3, **Edit Reports**, go back to step 3, and check the ones you
want. Then, when you advance to step 4, **Build Reports**, the reports
will appear in the **Select Report** drop-down list. If you need to
create new reports, go back to step 1, **Select Criteria**, and/or step
2, **Select Variables**. Remember to export any completed charts you
want to save by clicking **Done** and using the **Export Reports**
function before leaving the **Build Reports** screen. (For further
information, see **Section 4.I. Export Reports**.)

### 4.F. Significance Tests

Tests for statistical significance indicate whether observed differences
between estimates are likely to have occurred because of sampling error
or chance. "Significance" here does not imply any judgment about
absolute magnitude or educational relevance. It refers only to the
statistical nature of the difference and whether that difference likely
reflects a true difference in the population.

With your report of interest selected, click the **Significance Test**
link, which is located to the right of the **Chart** link (see exhibit
17), which will take you to the **Significance Test** window (exhibit
24). You first need to decide which variable you want to test and the
criterion by which you want to test it (i.e., between jurisdictions,
within variables, or across years). You will compare or look across the
variable's range of values, so it must have more than one value. You can
look across jurisdictions for a variable (that is, compare between two
or more jurisdictions) or you can look across the values within a
variable for a single jurisdiction. For example, with the variable shown
in exhibit 24, you could choose to compare scores of female students
between countries and subnational education systems, or you could choose
to compare scores of female students and male students.

The general steps for running significance tests are as follows (see
exhibit 24):

1.  In the **Significance Test** window, select either **Between
    > Jurisdictions**, **Within Variables**, or **Across Years**. Then,
    > select the appropriate jurisdiction(s), variable(s), year(s), and
    > statistic(s). For **Between Jurisdictions**, select at least two
    > jurisdictions. For **Within Variables**, select at least two
    > variables. For **Across Years**, more than one year needs to be
    > selected.

```{=html}
<!-- -->
```
27. You can enter a **Test Title** limited to 25 characters, using only
    > letters, numbers, spaces, underscores, and hyphens (otherwise, by
    > default, the test is named "Sig Test 1").

28. Select the output type as either **Table** or **Map**. The table
    > option will show the significance test results as a matrix. The
    > map option will show the significance test results on a world map,
    > highlighting the countries and subnational education systems that
    > have been selected. The map output is only available when
    > **Between Jurisdictions** is selected in the first step.

29. Additional options allow you to select **Show Table Details** to
    > display the estimates and standard errors for the table cells. If
    > you selected a map, this option is not applicable, as the map will
    > automatically show score details.

30. Click the **Preview** tab located in the upper-left corner or the
    > **Preview** button located in the bottom-left corner.

31. Click the **Edit** tab in the upper-left corner of the screen if you
    > wish to go back and make changes to the selections you made for
    > running the significance tests.

32. Click the **Done** button in the upper- or lower-right corner of the
    > screen to run the significance tests.

Exhibit 24. Significance test options

![Exhibit 24 is a screenshot from the ICILS IDE tool showing the
significance test options available in the Build Reports
tab.](images/chapter7/image23.png){width="6.5in" height="5.050694444444445in"}

When the table option is selected, you will get a significance test
matrix in which you will see the differences and *p* values. Using the
symbols shown in the legend of the matrix, an indication is also
provided of whether one estimate is significantly lower or higher than
another estimate or whether there is no significant difference (see
exhibit 25).

The alpha level for all *t* tests is .05. All comparisons within a
jurisdiction, within the same year, are made using dependent *t* tests.
Comparisons between jurisdictions are treated as independent, and
comparisons of achievement scores across years are made using
independent *t* tests with a linking error taken into account.

ICILS assessments are linked across years. That is, the sets of items
used to assess computer and information literacy (CIL) across years
include a subset of common items, referred to as link items. To
establish common reporting metrics for ICILS, the difficulty of the link
items, measured on different occasions, is compared. The comparison of
the item difficulties on the different occasions is used to determine a
score transformation that allows the reporting of the data on a common
scale. As each item provides slightly different information about the
link transformation, it follows that the chosen sample of link items
will influence the estimated transformation. The consequence is an
uncertainty in the transformation due to the sampling of link items,
just as there is an uncertainty in the country means due to the sampling
of students. The uncertainty that results from the link-item sampling is
referred to as the linking error, and this error must be taken into
account when making certain comparisons using the ICILS assessment data.
As with sampling errors, the likely range of magnitude for the errors is
represented as a standard error. Significance tests for scores across
years within the IDE take into account the linking errors applicable to
each display.

Exhibit 25. Significance test table output

![Exhibit 25 is a screenshot from the ICILS IDE tool showing an example
of a significance test table output in the Build Reports
tab.](images/chapter7/image24.png){width="6.5in" height="5.566666666666666in"}

When the **map option** is selected, a global map is shown with the
countries and subnational education systems selected shaded in different
colors (see exhibit 26). The focal jurisdiction is shaded in teal green,
with all other countries compared to it. The other countries are shaded
in colors that indicate whether they are higher, lower, or not
significantly different from the focal jurisdiction on whatever measure
has been selected. (Note that a light shade of gray is the default color
for jurisdictions not selected for comparison.) When you hover over a
jurisdiction, a text bubble displays the numerical difference in
estimates between that jurisdiction and the focal jurisdiction. At any
point, you may choose a different focal jurisdiction by clicking on
another country. You may also choose a different variable category for
comparison by using the drop‑down menu above the map.

Exhibit 26. Map of significance tests

![Exhibit 26 is a screenshot from the ICILS IDE tool showing an example
of a significance test map output in the Build Reports
tab.](images/chapter7/image25.png){width="6.5in" height="7.667361111111111in"}

### 4.G. Gap Analysis

Gap analysis is included in the IDE to compare differences in gaps shown
in a map, table, or chart. Gap differences can be compared between
jurisdictions and/or across years.

Exhibit 27. Gap analysis link selection

![Exhibit 27 is a screenshot from the ICILS IDE tool showing how to
select the gap analysis function in the Build Reports
tab.](images/chapter7/image26.png){width="6.5in" height="2.140277777777778in"}

With your report of interest selected, click on the **Gap Analysis**
link, which is located to the right of the **Significance Test** link
(see exhibit 27). You will need to decide which variable you would like
to test (e.g., gender) and the criterion by which you want to test it
(i.e., between jurisdictions or across years). The difference measure,
or gap, can be viewed between groups, between years, between groups and
years, or between percentiles within the selected variable. For example,
if you compute average CIL scores for two countries at two time points
for males and females, you can:

-   at one time point, compare the male-female gap in one country to the
    male-female gap in another country;

-   compare the male-female gap at two time points within a country;

-   compare the difference between the male-female gap at two time
    points in one country to the difference between the male-female gap
    at two time points in another country; or

-   compare the gap for females at two time points in one country to the
    gap for females at two time points in another country.

Exhibit 28. Gap analysis options

![Exhibit 28 is a screenshot from the ICILS IDE tool showing the gap
analysis options available in the Build Reports
tab.](images/chapter7/image27.png){width="6.5in" height="5.052083333333333in"}

The steps for running a gap analysis are similar to those for conducting
a statistical significance test (see exhibit 28). Thus, to run a gap
analysis, follow the instructions under **Section 4.F. Significance
Tests**, noting the following differences:

1.  The **Gap Analysis** link should be selected, not the **Significance
    > Test** link.

2.  The gap analysis does not have a **Within Variables** option for
    > analysis; the options are **Between Jurisdictions** and **Across
    > Years**.

3.  The difference measure (gap) of analysis must be selected from the
    > following: **Between Groups**, **Between Years**, **Between Groups
    > and Years**, and **Between Percentiles** (if variables are
    > selected for which a difference measure is not feasible, the
    > difference measure option will not appear as available in the Gap
    > Analysis menu).

The gap analysis output is presented in a format similar to that of the
significance test output, with one difference: the difference estimate
shown in the output is the difference between the gaps selected for
analysis. Note that you will still see the significance of these
differences, just like in a significance test. For example, exhibit 29
shows cross-national differences between male-female score gaps.

The gap analysis function computes and statistically tests differences
between score, percentage, or percentile gaps. For gap analysis tables,
all comparisons are independent tests with an alpha level of .05. Note
that the reference group for the gaps is kept constant during the
analysis, as opposed to taking the absolute value of the gaps.
Therefore, the gap analysis tests whether the magnitude of the gaps
differ from each other only when the gaps go in the same direction
(e.g., comparing a 5-point gender gap favoring females in one country
with a 15-point gender gap favoring females in another country).

Exhibit 29. Gap analysis output

![Exhibit 29 is a screenshot from the ICILS IDE tool showing an example
output report based on the gap analysis
options.](images/chapter7/image28.png){width="5.510415573053368in"
height="4.1875in"}

Note that a gap analysis across years cannot be combined with the
Between Years or Between Groups and Years difference measures, so you
will select the difference measure Between Groups, or, if you have
selected percentiles as one of your statistics, you may choose Between
Percentiles.

### 4.H. Regression Analysis

Regression analysis is included in the IDE to test for the relationship
between one or more independent variables with a dependent variable,
with the independent variables controlling for each other. The type of
analysis performed in this feature of the IDE is referred to as linear
regression, with the dependent variable being a continuous variable
selected at step 1. To run a regression, first, go to **Build Reports**
and choose the report of interest from the drop-down **Select Report**
menu. Then click on the **Regression Analysis** link, which is to the
right of the **Gap Analysis** link (see exhibit 30).

Exhibit 30. Regression analysis link selection

![Exhibit 30 is a screenshot from the ICILS IDE tool showing how to
select the regression analysis function in the Build Reports
tab.](images/chapter7/image29.png){width="6.5in" height="2.1256944444444446in"}

The general steps for running a regression analysis are as follows (see
exhibit 31):

1.  In the **Regression Analysis** pop-up window, you can enter a
    **Name** limited to 25 characters, using only letters, numbers,
    spaces, underscores, and hyphens (otherwise, by default, the test
    will be named "Regression 1").

2.  Select the appropriate jurisdiction, year, and variable(s) for
    analysis. Please note that you may only choose one jurisdiction and
    year at a time, but you may choose up to three independent variables
    to be in your report. In order to use up to three independent
    variables, you must have already created and selected a
    cross-tabulated report (by selecting three variables in Step 2,
    **Select Variables**).

3.  Click the **Preview** tab located in the upper-left corner to view
    the table format into which your output will be populated. In the
    Preview tab, an "X" denotes where the output will display.

4.  Click the **Edit** tab in the upper-left corner of the screen if you
    wish to go back and make changes to the selections you made for
    running the analysis.

5.  Click the **Done** button in the upper- or lower-right corner of the
    screen to run the regression analysis.

Exhibit 31: Regression analysis options

![Exhibit 31 is a screenshot from the ICILS IDE tool showing the options
for the regression analysis
output.](images/chapter7/image30.png){width="6.22916447944007in"
height="3.2708333333333335in"}

After you have clicked **Done**, your regression analysis output will
load onto the screen (see exhibit 32). A 0-1 contrast coding is used to
code the independent variable, where the first subgroup of the
independent variable is the reference group. Using dummy-coded variables
in linear regression is useful for comparing each subgroup against a
reference group. For example, in exhibit 32, if the subgroup "Students
and/or at least one parent born in country of test" is the reference
group for the independent variable **Immigration status (SIMMIG)**, the
IDE creates a "Student born in country of test but both/only parent(s)
born abroad" dummy variable (1 if yes, 0 if no) and a "Student and
both/only parent(s) born abroad" dummy variable (1 if yes, 0 if no). The
reference group is excluded from the regression analysis.

Exhibit 32. Regression analysis output

![Exhibit 32 is a screenshot from the ICILS IDE tool showing an example
of the regression analysis output.](images/chapter7/image31.png){width="6.5in"
height="3.3513888888888888in"}

Using the output from the regression analysis, you can compare the
average CIL scores of first‑generation (Student and both/only parent(s)
born abroad) and second-generation (Student born in country of test but
both/only parent(s) born abroad) students to scores of native-born
(Students and/or at least one parent born in country of test) students.
When a single dummy‑coded variable is used in a regression, the
*intercept* is the mean of the reference group (e.g., 522.0007), and the
*regression coefficient* is the difference between the mean of the
reference group and the group identified (coded 1) with the dummy-coded
variable (e.g., −40.2344 for second generation and −20.0819 for first
generation). Since the regression coefficients are presented with a
standard error and a *t* value, they can be used to test whether a
difference between means is statistically significant. Under the
Significance column in the output, you will see three possible signs:
(1) \< signifies a significant negative difference, (2) \> signifies a
significant positive difference, and (3) x signifies the difference is
not statistically significant.

### 4.I. Export Reports

Click on the **Export Reports** button/arrow located on the right side
of the **Build Reports** screen to save or print your tables, charts,
and significance tests. The report names that appear in the **Export
Reports** window are those that were checked off at step 3, **Edit
Reports**.

Check the files you want to export and select one of the file formats:
**HTML** (print-friendly), **Excel**, **Word**, or **PDF** (see exhibit
33). All reports that you select at the same time will be exported in
one file. In the Excel format, you will be able to increase the decimal
places visible wherever more precision is available. Because there are
many different operating systems in use, you may get an error message
with Excel or one of the other formats. Usually, this will not affect
your ability to export, so please wait for the software errors to
resolve.

Exhibit 33. Export report options

![Exhibit 33 is a screenshot from the ICILS IDE tool showing the export
options, including HTML, Excel, Word, and
PDF.](images/chapter7/image32.png){width="3.3478258967629047in"
height="3.4608694225721783in"}

